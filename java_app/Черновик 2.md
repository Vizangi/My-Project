Конечно, давайте максимально подробно разберем, как поднять ваше приложение `CreditPipelineApplication` с использованием Docker Compose, настроим мониторинг, логирование и подключим базу данных PostgreSQL и стек ELK.

**Шаг 1: Подготовка окружения**

1.  **Установите Docker:** Если у вас еще не установлен Docker, вам необходимо его скачать и установить. Перейдите на официальный сайт Docker ([https://www.docker.com/products/docker-desktop/](https://www.docker.com/products/docker-desktop/)) и следуйте инструкциям для вашей операционной системы.
2.  **Установите Docker Compose:** Docker Compose обычно устанавливается вместе с Docker Desktop. Если у вас возникли проблемы, обратитесь к официальной документации Docker Compose ([https://docs.docker.com/compose/install/](https://docs.docker.com/compose/install/)).

**Шаг 2: Создание структуры проекта**

Для удобства организации создайте следующую структуру каталогов в любом удобном для вас месте:

```
credit-pipeline-app/
├── src/
│   └── main/
│       └── java/
│           └── com/
│               └── example/
│                   └── creditpipeline/
│                       └── CreditPipelineApplication.java
│                       └── ... (остальные файлы вашего кода)
├── Dockerfile
├── docker-compose.yml
├── docker-compose-app.yml
├── docker-compose-db.yml
├── docker-compose-elk.yml
├── docker-compose-prometheus.yml
└── docker-compose-global.yml
```

Скопируйте ваш исходный код (`CreditPipelineApplication.java` и другие файлы) в соответствующие каталоги внутри `src/main/java/com/example/creditpipeline/`.

**Шаг 3: Создание Dockerfile для приложения**

В корневой директории `credit-pipeline-app` создайте файл с именем `Dockerfile` и запишите в него следующее содержимое:

```dockerfile
FROM openjdk:17-jdk-slim

WORKDIR /app

# Копируем собранный JAR-файл приложения (предполагается, что сборка выполняется отдельно)
COPY target/*.jar app.jar

# Открываем порт, на котором работает приложение (обычно 8080 для Spring Boot)
EXPOSE 8080

# Команда для запуска приложения
ENTRYPOINT ["java", "-jar", "app.jar"]
```

**Важно:** Этот `Dockerfile` предполагает, что вы предварительно собрали ваше Spring Boot приложение в JAR-файл. Обычно это делается с помощью Maven (`mvn clean package`) или Gradle (`./gradlew bootJar`). Собранный JAR-файл будет находиться в каталоге `target` (для Maven) или `build/libs` (для Gradle). Перед запуском Docker Compose убедитесь, что вы выполнили сборку вашего приложения.

**Шаг 4: Создание отдельных файлов Docker Compose**

Теперь создадим отдельные файлы `docker-compose-*.yml` для каждого компонента.

**4.1. `docker-compose-app.yml` (Docker Compose для приложения)**

```yaml
version: '3.8'
services:
  credit-pipeline-app:
    build: .
    image: credit-pipeline-app:latest
    ports:
      - "8080:8080"
    environment:
      - SPRING_DATASOURCE_URL=jdbc:postgresql://credit-pipeline-db:5432/credit_pipeline_db
      - SPRING_DATASOURCE_USERNAME=pipeline_user
      - SPRING_DATASOURCE_PASSWORD=pipeline_password
      - SPRING_JPA_HIBERNATE_DDL_AUTO=update # Или create-drop для тестов
    depends_on:
      - credit-pipeline-db
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
```

* `version: '3.8'`: Указывает версию синтаксиса Docker Compose.
* `services:`: Определяет сервисы, входящие в наше приложение.
* `credit-pipeline-app:`: Название нашего сервиса с приложением.
    * `build: .`: Указывает, что Dockerfile находится в текущей директории.
    * `image: credit-pipeline-app:latest`: Название Docker-образа, который будет создан.
    * `ports: - "8080:8080"`: Пробрасывает порт 8080 с контейнера на порт 8080 хост-машины. Вы сможете обращаться к приложению по адресу `http://localhost:8080`.
    * `environment:`: Определяет переменные окружения, которые будут доступны приложению. Здесь мы настраиваем подключение к PostgreSQL.
        * `SPRING_DATASOURCE_URL`: URL для подключения к базе данных PostgreSQL. Обратите внимание на `credit-pipeline-db` - это имя сервиса PostgreSQL, которое Docker Compose автоматически разрешает в IP-адрес контейнера.
        * `SPRING_DATASOURCE_USERNAME`, `SPRING_DATASOURCE_PASSWORD`: Учетные данные для подключения к базе данных.
        * `SPRING_JPA_HIBERNATE_DDL_AUTO`: Указывает, как Hibernate будет работать со схемой базы данных. `update` попытается обновить схему, не удаляя данные. `create-drop` создаст схему при запуске и удалит ее при остановке (подходит для разработки).
    * `depends_on: - credit-pipeline-db`: Указывает, что сервис `credit-pipeline-app` должен запускаться после того, как будет запущен сервис `credit-pipeline-db`.
    * `logging:`: Настройка логирования для Docker. Мы используем драйвер `json-file` с ограничением размера и количества файлов.

**4.2. `docker-compose-db.yml` (Docker Compose для PostgreSQL)**

```yaml
version: '3.8'
services:
  credit-pipeline-db:
    image: postgres:15-alpine
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=pipeline_user
      - POSTGRES_PASSWORD=pipeline_password
      - POSTGRES_DB=credit_pipeline_db
    volumes:
      - db_data:/var/lib/postgresql/data/
volumes:
  db_data:
```

* `image: postgres:15-alpine`: Используем официальный образ PostgreSQL версии 15 на базе Alpine Linux (легкий дистрибутив).
* `ports: - "5432:5432"`: Пробрасывает порт 5432 PostgreSQL с контейнера на порт 5432 хост-машины.
* `environment:`: Настройка переменных окружения для PostgreSQL.
    * `POSTGRES_USER`, `POSTGRES_PASSWORD`, `POSTGRES_DB`: Учетные данные и название базы данных, которые будут созданы при первом запуске контейнера. Эти же данные мы используем в настройках приложения.
* `volumes: - db_data:/var/lib/postgresql/data/`: Создает именованный том `db_data` и монтирует его в каталог `/var/lib/postgresql/data/` внутри контейнера. Это обеспечивает сохранение данных PostgreSQL между перезапусками контейнера.
* `volumes: db_data:`: Определение именованного тома.

**4.3. `docker-compose-elk.yml` (Docker Compose для стека ELK)**

```yaml
version: '3.8'
services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.1
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - esdata:/usr/share/elasticsearch/data
    networks:
      - elk

  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.1
    container_name: logstash
    ports:
      - "5044:5044" # Beats input
      - "9600:9600" # мониторинг Logstash
    environment:
      - XPACK_MONITORING_ENABLED=false
    volumes:
      - ./logstash/pipeline:/usr/share/logstash/pipeline
      - /var/run/docker.sock:/var/run/docker.sock # Для доступа к логам Docker
    depends_on:
      - elasticsearch
    networks:
      - elk

  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.1
    container_name: kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=["http://elasticsearch:9200"]
    depends_on:
      - elasticsearch
    networks:
      - elk

networks:
  elk:
    driver: bridge

volumes:
  esdata:
```

* `elasticsearch:`: Сервис Elasticsearch.
    * `discovery.type=single-node`: Настройка для одноузлового кластера (для разработки).
    * `xpack.security.enabled=false`: Отключаем систему безопасности (для простоты, в production рекомендуется включить).
    * `volumes: - esdata:/usr/share/elasticsearch/data`: Том для хранения данных Elasticsearch.
* `logstash:`: Сервис Logstash.
    * `volumes:`:
        * `./logstash/pipeline:/usr/share/logstash/pipeline`: Монтируем локальную директорию `logstash/pipeline` (которую нам еще предстоит создать) в каталог с конфигурацией Logstash.
        * `/var/run/docker.sock:/var/run/docker.sock`: Предоставляем Logstash доступ к сокету Docker, чтобы он мог получать логи контейнеров.
    * `depends_on: - elasticsearch`: Запускается после Elasticsearch.
* `kibana:`: Сервис Kibana (веб-интерфейс для визуализации данных).
    * `ELASTICSEARCH_HOSTS`: Указываем адрес Elasticsearch.
    * `depends_on: - elasticsearch`: Запускается после Elasticsearch.
* `networks: elk:`: Определяем общую сеть `elk` для взаимодействия сервисов.
* `volumes: esdata:`: Определяем том для Elasticsearch.

Вам нужно создать директорию `logstash` в корне проекта и внутри нее директорию `pipeline`. В `logstash/pipeline` создайте файл `logstash.conf` со следующим содержимым для сбора логов Docker:

```
input {
  docker {
    host => "unix:///var/run/docker.sock"
    containers => "all"
    remove_tag_config => true
    decorate_message => true
  }
}

filter {
  if [docker][container][name] == "credit-pipeline-app" {
    grok {
      match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level}%{SPACE}%{DATA:pid}%{SPACE}---%{SPACE}\\[%{DATA:thread}\\]%{SPACE}%{DATA:logger}%{SPACE}:%{SPACE}%{GREEDYDATA:log_message}" }
      remove_field => "message"
    }
    date {
      match => [ "timestamp", "yyyy-MM-dd HH:mm:ss.SSS" ]
      target => "@timestamp"
      timezone => "Europe/Moscow" # Или ваш часовой пояс
    }
  }
}

output {
  elasticsearch {
    hosts => [ "http://elasticsearch:9200" ]
    index => "credit-pipeline-logs-%{+YYYY.MM.dd}"
  }
  stdout { codec => rubydebug }
}
```

Этот файл конфигурации Logstash:

* **input:** Настраивает входной плагин `docker` для получения логов от Docker.
* **filter:** Применяет фильтр Grok для разбора логов приложения `credit-pipeline-app` в структурированные поля. Затем парсит поле `timestamp` в формат даты.
* **output:** Отправляет обработанные логи в Elasticsearch в индекс `credit-pipeline-logs-YYYY.MM.dd` и выводит их на стандартный вывод для отладки.

**4.4. `docker-compose-prometheus.yml` (Docker Compose для Prometheus)**

Для сбора метрик Prometheus нам понадобится добавить зависимость в ваше Spring Boot приложение. Добавьте в ваш `pom.xml` (если используете Maven) или `build.gradle` (если используете Gradle) следующую зависимость:

**Maven (`pom.xml`):**

```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>
```

**Gradle (`build.gradle`):**

```gradle
implementation 'org.springframework.boot:spring-boot-starter-actuator'
```

После добавления зависимости Spring Boot Actuator начнет автоматически предоставлять различные метрики, включая метрики Prometheus, по умолчанию на эндпоинте `/actuator/prometheus`.

Теперь создайте файл `docker-compose-prometheus.yml`:

```yaml
version: '3.8'
services:
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    depends_on:
      - credit-pipeline-app
    networks:
      - monitoring

networks:
  monitoring:
    driver: bridge
```

* `image: prom/prometheus:latest`: Используем официальный образ Prometheus.
* `ports: - "9090:9090"`: Пробрасываем порт 9090 для доступа к веб-интерфейсу Prometheus.
* `volumes: - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro`: Монтируем локальный файл конфигурации Prometheus (`prometheus/prometheus.yml`) в контейнер. `:ro` означает, что файл монтируется только для чтения.
* `depends_on: - credit-pipeline-app`: Запускается после приложения.
* `networks: monitoring:`: Определяем сеть для Prometheus.

Создайте директорию `prometheus` в корне проекта и внутри нее файл `prometheus.yml` со следующей конфигурацией:

```yaml
global:
  scrape_interval:     15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'credit-pipeline-app'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: ['credit-pipeline-app:8080']
```

Эта конфигурация указывает Prometheus опрашивать эндпоинт `/actuator/prometheus` сервиса `credit-pipeline-app` на порту 8080 каждые 15 секунд для сбора метрик.

**Шаг 5: Создание глобального файла `docker-compose-global.yml`**

Этот файл объединит все наши сервисы:

```yaml
version: '3.8'
services:
  credit-pipeline-app:
    build: .
    image: credit-pipeline-app:latest
    ports:
      - "8080:8080"
    environment:
      - SPRING_DATASOURCE_URL=jdbc:postgresql://credit-pipeline-db:5432/credit_pipeline_db
      - SPRING_DATASOURCE_USERNAME=pipeline_user
      - SPRING_DATASOURCE_PASSWORD=pipeline_password
      - SPRING_JPA_HIBERNATE_DDL_AUTO=update
    depends_on:
      - credit-pipeline-db
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
    networks:
      - app-network

  credit-pipeline-db:
    image: postgres:15-alpine
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=pipeline_user
      - POSTGRES_PASSWORD=pipeline_password
      - POSTGRES_DB=credit_pipeline_db
    volumes:
      - db_data:/var/lib/postgresql/data/
    networks:
      - app-network

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.1
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - esdata:/usr/share/elasticsearch/data
    networks:
      - elk-network

  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.1
    container_name: logstash
    ports:
      - "5044:5044"
      - "9600:9600"
    environment:
      - XPACK_MONITORING_ENABLED=false
    volumes:
      - ./logstash/pipeline:/usr/share/logstash/pipeline
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      - elasticsearch
    networks:
      - elk-network

  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.1
    container_name: kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=["http://elasticsearch:9200"]
    depends_on:
      - elasticsearch
    networks:
      - elk-network

  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    depends_on:
      - credit-pipeline-app
    networks:
      - monitoring-network

networks:
  app-network:
    driver: bridge
  elk-network:
    driver: bridge
  monitoring-network:
    driver: bridge

volumes:
  db_data:
  esdata:
```

Обратите внимание, что каждый сервис теперь находится в своей сети для лучшей изоляции.

**Шаг 6: Запуск приложения с помощью Docker Compose**

Перейдите в корневую директорию `credit-pipeline-app` в вашем терминале.

**Для запуска отдельных компонентов:**

* **Приложение и база данных:**
    ```bash
    docker compose -f docker-compose-app.yml -f docker-compose-db.yml up -d
    ```
* **Стек ELK:**
    ```bash
    docker compose -f docker-compose-elk.yml up -d
    ```
* **Prometheus:**
    ```bash
    docker compose -f docker-compose-prometheus.yml up -d
    ```

**Для запуска всех компонентов одновременно (используя глобальный файл):**

```bash
docker compose -f docker-compose-global.yml up -d
```

Команда `up -d` запустит контейнеры в фоновом режиме.

**Шаг 7: Доступ к приложению, API и логам**

* **Приложение:** После запуска вы сможете обратиться к вашему приложению по адресу `http://localhost:8080`.
* **API:** Эндпоинты API, определенные в вашем контроллере (`PipelineController`), будут доступны по адресу `http://localhost:8080/api/pipeline`. Например:
    * Отправка новой заявки: `POST http://localhost:8080/api/pipeline/submit` (тело запроса может быть JSON с данными заявителя и суммой).
    * Получение всех заявок: `GET http://localhost:8080/api/pipeline/applications`.
    * Получение заявки по ID: `GET http://localhost:8080/api/pipeline/applications/{id}`.
* **Логи приложения:**
    * **Через Docker:** Вы можете просматривать логи контейнера приложения с помощью команды:
        ```bash
        docker logs -f credit-pipeline-app
        ```
    * **Через Kibana (ELK):**
        1.  Откройте Kibana в вашем браузере по адресу `http://localhost:5601`.
        2.  При первом запуске вам может потребоваться настроить индекс. Выберите индекс `credit-pipeline-logs-*`.
        3.  Перейдите в раздел "Discover", где вы сможете фильтровать, искать и анализировать логи вашего приложения.
* **Метрики Prometheus:**
    1.  Откройте веб-интерфейс Prometheus по адресу `http://localhost:9090`.
    2.  В поле "Expression" вы можете вводить запросы PromQL для просмотра различных метрик вашего приложения, например:
        * `jvm_memory_used_bytes`: Использование памяти JVM.
        * `http_server_requests_seconds_count`: Количество HTTP-запросов.
        * `process_cpu_usage`: Использование CPU процессом приложения.
        * `tomcat_sessions_active_current`: Количество активных сессий Tomcat (если используется).
        * `spring_data_source_hikari_connections_active`: Количество активных подключений к базе данных HikariCP.

**Шаг 8: Остановка приложения**

Чтобы остановить все запущенные контейнеры, выполните в корневой директории проекта:

```bash
docker compose -f docker-compose-global.yml down
```

Или для отдельных компонентов используйте соответствующие файлы `-f`.

**Метрики для Prometheus:**

Как упоминалось выше, после добавления Spring Boot Actuator и настройки Prometheus, вы сможете видеть множество стандартных метрик. Вот некоторые примеры, которые могут быть полезны для вашего приложения:

* **JVM Metrics:**
    * `jvm_memory_used_bytes`: Использование памяти JVM (различные области, такие как heap и non-heap).
    * `jvm_memory_max_bytes`: Максимальное количество памяти, доступное JVM.
    * `jvm_gc_live_data_size_bytes`: Размер "живых" объектов в куче после последней сборки мусора.
    * `jvm_gc_max_data_size_bytes`: Максимальный размер кучи, который может быть использован для "живых" объектов.
    * `jvm_gc_collection_seconds_count`: Количество сборок мусора.
    * `jvm_gc_collection_seconds_sum`: Общее время, затраченное на сборку мусора.
    * `jvm_threads_live`: Количество активных потоков JVM.
    * `jvm_threads_peak`: Пиковое количество потоков JVM с момента запуска.
* **Tomcat Metrics (если используется встроенный Tomcat):**
    * `tomcat_sessions_active_current`: Количество активных сессий.
    * `tomcat_sessions_created_total`: Общее количество созданных сессий.
    * `tomcat_sessions_expired_total`: Общее количество истекших сессий.
* **HTTP Request Metrics:**
    * `http_server_requests_seconds_count`: Общее количество HTTP-запросов.
    * `http_server_requests_seconds_sum`: Общее время обработки HTTP-запросов.
    * `http_server_requests_seconds_max`: Максимальное время обработки HTTP-запроса.
    * Метрики с разбивкой по статусам ответов (например, `http_server_requests_seconds_count{status="200"}`).
* **Spring Data Source (HikariCP) Metrics:**
    * `spring_datasource_hikari_connections_active`: Количество активных подключений к базе данных.
    * `spring_datasource_hikari_connections_idle`: Количество простаивающих подключений к базе данных.
    * `spring_datasource_hikari_connections_creation_seconds_count`: Количество попыток создания подключения.
    * `spring_datasource_hikari_connections_creation_seconds_sum`: Общее время, затраченное на создание подключений.
* **Custom Metrics:** Вы также можете создавать свои собственные метрики с помощью аннотаций `@Timed`, `@Counted`, `@Gauge` из библиотеки Micrometer, которая интегрирована со Spring Boot Actuator.

**API и Логи:**

* **API:** Как уже было описано, API вашего приложения доступен по адресу `http://localhost:8080/api/pipeline`. Вы можете использовать такие инструменты, как `curl`, Postman или Insomnia для взаимодействия с API.
* **Логи:** Логи приложения пишутся с использованием SLF4j. В Docker-контейнере они будут доступны через стандартный вывод Docker. Мы также настроили Logstash для сбора и обработки этих логов, чтобы вы могли просматривать их в Kibana. Обратите внимание на использование `MDC` (Mapped Diagnostic Context) в вашем коде. Это позволяет добавлять в логи контекстную информацию, такую как `traceId` и `applicationId`, что очень полезно для отслеживания запросов.

**Compose для PostgreSQL и вывод данных:**

Мы уже создали `docker-compose-db.yml` и включили его в `docker-compose-global.yml`. Ваше приложение настроено для подключения к PostgreSQL через переменные окружения. Spring Data JPA автоматически создаст таблицы на основе ваших сущностей (`CreditApplication`). Данные, создаваемые вашим приложением (например, при вызове `pipelineService.processApplication`), будут автоматически сохраняться в таблице `credit_applications` в базе данных PostgreSQL.

**Compose для стека ELK:**

Мы также создали `docker-compose-elk.yml` и включили его в `docker-compose-global.yml`. Logstash настроен для сбора логов Docker и отправки их в Elasticsearch. Kibana предоставляет веб-интерфейс для просмотра и анализа этих логов.

**Отдельные Compose и глобальный Compose:**

Как вы и просили, мы создали отдельные файлы `docker-compose-app.yml`, `docker-compose-db.yml`, `docker-compose-elk.yml`, `docker-compose-prometheus.yml` для каждого компонента, а также один глобальный файл `docker-compose-global.yml`, который объединяет все сервисы. Использование глобального файла минимизирует труд при запуске и остановке всего стека.

**Дополнительные замечания:**

* Перед первым запуском убедитесь, что вы собрали ваше Spring Boot приложение (например, с помощью `mvn clean package`).
* Проверьте, что порты 8080, 5432, 9200, 9300, 5601 и 9090 не заняты на вашей хост-машине.
* В production-окружении вам следует более серьезно подойти к вопросам безопасности (например, включить аутентификацию в Elasticsearch и Kibana) и настройке томов для хранения данных.
* Конфигурацию Logstash можно настроить более детально в зависимости от ваших потребностей в анализе логов.

Теперь у вас есть полное руководство по развертыванию вашего приложения с использованием Docker Compose, включая мониторинг, логирование и базу данных. Удачи!
